"""
Prompt Templates - LLM 提示词模板
"""
from typing import Dict, Any, Optional, List
import json


class PromptTemplates:
    """
    LLM 提示词模板类，包含各种分析和生成任务的提示词
    """

    SYSTEM_PROMPT = """你是一个专业的网络安全专家，专注于Web应用渗透测试。
你的任务是分析HTTP请求和响应，识别潜在的安全漏洞。
你必须遵守道德规范，只用于授权的安全测试。

分析时请注意：
1. 准确识别漏洞类型
2. 评估漏洞的严重程度
3. 提供详细的漏洞描述
4. 给出可行的修复建议
5. 始终保持专业和客观

请以JSON格式返回分析结果，确保格式正确。"""

    @staticmethod
    def get_system_prompt() -> str:
        """获取系统提示"""
        return PromptTemplates.SYSTEM_PROMPT

    @staticmethod
    def vulnerability_analysis_prompt(request_data: Dict[str, Any],
                                     response_data: Dict[str, Any],
                                     context: Optional[Dict] = None) -> str:
        """
        生成漏洞分析的提示词

        Args:
            request_data: 请求数据
            response_data: 响应数据
            context: 额外的上下文信息

        Returns:
            提示词字符串
        """
        prompt = f"""请分析以下HTTP请求和响应对是否存在安全漏洞。

## 请求数据
```json
{json.dumps(request_data, indent=2, ensure_ascii=False)}
```

## 响应数据
```json
{json.dumps(response_data, indent=2, ensure_ascii=False)}
```
"""

        if context:
            prompt += f"\n## 上下文信息\n```json\n{json.dumps(context, indent=2, ensure_ascii=False)}\n```\n"

        prompt += """
请返回JSON格式的分析结果，包含以下字段：
{
  "has_vulnerability": true/false,
  "vulnerability_type": "漏洞类型（如SQL Injection, XSS, RCE等）",
  "severity": "CRITICAL/HIGH/MEDIUM/LOW",
  "confidence": "0-1之间的置信度",
  "description": "漏洞描述",
  "evidence": "支持该判断的证据",
  "suggested_payloads": ["建议的测试payload列表"],
  "remediation": "修复建议"
}

如果没有发现漏洞，将 has_vulnerability 设为 false，其他字段留空或设为 null。
"""
        return prompt

    @staticmethod
    def payload_suggestion_prompt(endpoint: str, parameter: str,
                                 vuln_type: str,
                                 context: Optional[Dict] = None) -> str:
        """
        生成 Payload 建议的提示词

        Args:
            endpoint: 目标端点
            parameter: 参数名
            vuln_type: 漏洞类型
            context: 额外的上下文信息

        Returns:
            提示词字符串
        """
        prompt = f"""请为以下情况生成针对性的测试Payload。

## 目标信息
- 端点: {endpoint}
- 参数: {parameter}
- 漏洞类型: {vuln_type}
"""

        if context:
            prompt += f"\n## 上下文信息\n```json\n{json.dumps(context, indent=2, ensure_ascii=False)}\n```\n"

        prompt += """
请返回JSON格式的结果，包含以下字段：
{
  "payloads": [
    {
      "payload": "具体payload",
      "description": "payload说明",
      "expected_behavior": "预期行为"
    }
  ],
  "testing_strategy": "测试策略说明"
}

确保payload是有效的、可以实际测试的。
"""
        return prompt

    @staticmethod
    def response_explanation_prompt(response_body: str,
                                   vuln_type: str) -> str:
        """
        生成响应解释的提示词

        Args:
            response_body: 响应体内容
            vuln_type: 正在测试的漏洞类型

        Returns:
            提示词字符串
        """
        # 截断过长的响应体
        max_body_length = 2000
        truncated_body = response_body[:max_body_length]
        if len(response_body) > max_body_length:
            truncated_body += "\n... (内容已截断)"

        prompt = f"""请解释以下HTTP响应是否表明存在{vuln_type}漏洞。

## 响应内容
```
{truncated_body}
```

请分析：
1. 响应中的哪些特征表明可能存在漏洞？
2. 响应状态码的含义
3. 响应体中是否有错误信息、异常行为等？
4. 这是否是一个正常的响应，还是存在异常？

请给出详细的分析结论。
"""
        return prompt

    @staticmethod
    def tech_stack_analysis_prompt(headers: Dict[str, str],
                                  body: str) -> str:
        """
        生成技术栈分析的提示词

        Args:
            headers: HTTP 响应头
            body: HTTP 响应体

        Returns:
            提示词字符串
        """
        # 截断过长的响应体
        max_body_length = 1000
        truncated_body = body[:max_body_length]
        if len(body) > max_body_length:
            truncated_body += "\n... (内容已截断)"

        prompt = f"""请分析以下HTTP响应，识别目标使用的技术栈。

## 响应头
```json
{json.dumps(headers, indent=2, ensure_ascii=False)}
```

## 响应体
```
{truncated_body}
```

请返回JSON格式的分析结果，包含以下字段：
{
  "server": "服务器软件",
  "programming_language": "编程语言",
  "framework": "使用的框架",
  "database": "可能的数据库",
  "other_technologies": ["其他技术"],
  "confidence": "0-1之间的置信度",
  "evidence": "判断依据"
}
"""
        return prompt

    @staticmethod
    def endpoint_discovery_prompt(html_content: str,
                                 base_url: str) -> str:
        """
        生成端点发现的提示词

        Args:
            html_content: HTML 内容
            base_url: 基础 URL

        Returns:
            提示词字符串
        """
        # 截断过长的 HTML
        max_html_length = 3000
        truncated_html = html_content[:max_html_length]
        if len(html_content) > max_html_length:
            truncated_html += "\n... (内容已截断)"

        prompt = f"""请分析以下HTML内容，发现可能的API端点和敏感路径。

基础URL: {base_url}

## HTML内容
```
{truncated_html}
```

请返回JSON格式的结果，包含以下字段：
{
  "endpoints": [
    {
      "path": "发现的路径",
      "method": "可能的HTTP方法",
      "description": "端点描述",
      "suspicious": true/false
    }
  ],
  "forms": [
    {
      "action": "表单action",
      "method": "表单method",
      "fields": ["字段列表"],
      "description": "表单描述"
    }
  ],
  "sensitive_paths": ["可能的敏感路径"],
  "javascript_files": ["发现的JS文件"],
  "comments_with_info": ["包含信息的注释"]
}
"""
        return prompt

    @staticmethod
    def attack_surface_analysis_prompt(endpoints: List[Dict[str, Any]],
                                     tech_stack: Dict[str, str]) -> str:
        """
        生成攻击面分析的提示词

        Args:
            endpoints: 端点列表
            tech_stack: 技术栈信息

        Returns:
            提示词字符串
        """
        prompt = f"""请分析以下目标的攻击面，确定测试优先级。

## 技术栈
```json
{json.dumps(tech_stack, indent=2, ensure_ascii=False)}
```

## 发现的端点
```json
{json.dumps(endpoints, indent=2, ensure_ascii=False)}
```

请返回JSON格式的分析结果，包含以下字段：
{
  "high_priority_endpoints": [
    {
      "endpoint": "端点路径",
      "priority": "优先级理由",
      "vulnerability_types": ["可能存在的漏洞类型"],
      "testing_strategy": "测试策略"
    }
  ],
  "recommendations": ["测试建议"],
  "attack_surface_summary": "攻击面总结"
}
"""
        return prompt
